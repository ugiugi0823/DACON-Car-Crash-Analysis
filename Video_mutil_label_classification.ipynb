{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Video-mutil-label-classification"
      ],
      "metadata": {
        "id": "W7Pk6TCPraXC"
      },
      "id": "W7Pk6TCPraXC"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Download"
      ],
      "metadata": {
        "id": "dS2IZ9c2rUu2"
      },
      "id": "dS2IZ9c2rUu2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5471bf37-978d-4b72-931e-bc5bab4b9225",
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "tags": [],
        "id": "5471bf37-978d-4b72-931e-bc5bab4b9225",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29820ee-deaa-49d7-c11a-907804da19bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (1.21.6)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (1.3.5)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from pandas) (1.21.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting decord\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.8/dist-packages (from decord) (1.21.6)\n",
            "Installing collected packages: decord\n",
            "Successfully installed decord-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/, https://download.pytorch.org/whl/cu117\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.1+cu116)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.8/dist-packages (0.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.25.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.21.6)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2022.12.7)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-1.9.2-py3-none-any.whl (826 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m826.2/826.2 KB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.5.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.13.1+cu116)\n",
            "Collecting torchmetrics>=0.7.0\n",
            "  Downloading torchmetrics-0.11.1-py3-none-any.whl (517 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m517.2/517.2 KB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (1.21.6)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (23.0)\n",
            "Collecting lightning-utilities>=0.6.0.post0\n",
            "  Downloading lightning_utilities-0.6.0.post0-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (2023.1.0)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.8/dist-packages (from pytorch-lightning) (4.64.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (3.8.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.25.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (1.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (3.0.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.24.3)\n",
            "Installing collected packages: lightning-utilities, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.6.0.post0 pytorch-lightning-1.9.2 torchmetrics-0.11.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorchvideo\n",
            "  Downloading pytorchvideo-0.1.5.tar.gz (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 KB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting av\n",
            "  Downloading av-10.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parameterized\n",
            "  Downloading parameterized-0.8.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting iopath\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 KB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.8/dist-packages (from pytorchvideo) (3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorchvideo) (1.21.6)\n",
            "Collecting yacs>=0.1.6\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorchvideo) (6.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorchvideo) (4.64.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorchvideo) (2.2.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorchvideo) (7.1.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.8/dist-packages (from fvcore->pytorchvideo) (0.8.10)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.8/dist-packages (from iopath->pytorchvideo) (4.5.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: pytorchvideo, fvcore, iopath\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorchvideo: filename=pytorchvideo-0.1.5-py3-none-any.whl size=188715 sha256=ef9042dbed7289469914eab1c0a448770df0028b7431484f038fb5b8d548ce65\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/62/e5/0b41f2deb978f449ba3efb4bb24efd6962e4b6abb1fae544ee\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61431 sha256=f60082599e7d95aa58ec97e7b9035573a1cce8846b41536b1cb6df9a484efbf7\n",
            "  Stored in directory: /root/.cache/pip/wheels/b8/79/07/c0e9367f5b5ea325e246bd73651e8af175fabbef943043b1cc\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31547 sha256=5cb4b4e4a38521e88ef6d0445f11610eb173201eedc30e4d23fa279164002dc9\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/3e/24/0f349c0b2eeb6965903035f3b00dbb5c9bea437b4a2f18d82c\n",
            "Successfully built pytorchvideo fvcore iopath\n",
            "Installing collected packages: parameterized, av, yacs, portalocker, iopath, fvcore, pytorchvideo\n",
            "Successfully installed av-10.0.0 fvcore-0.1.5.post20221221 iopath-0.1.10 parameterized-0.8.1 portalocker-2.7.0 pytorchvideo-0.1.5 yacs-0.1.8\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (1.0.2)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 KB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn\n",
            "Successfully installed scikit-multilearn-0.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation-models-pytorch\n",
            "  Downloading segmentation_models_pytorch-0.3.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting efficientnet-pytorch==0.7.1\n",
            "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (4.64.1)\n",
            "Collecting pretrainedmodels==0.7.4\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting timm==0.6.12\n",
            "  Downloading timm-0.6.12-py3-none-any.whl (549 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m549.1/549.1 KB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /usr/local/lib/python3.8/dist-packages (from segmentation-models-pytorch) (0.14.1+cu116)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.13.1+cu116)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from timm==0.6.12->segmentation-models-pytorch) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (4.5.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub->timm==0.6.12->segmentation-models-pytorch) (3.9.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from munch->pretrainedmodels==0.7.4->segmentation-models-pytorch) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (4.0.0)\n",
            "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n",
            "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16446 sha256=8b29079afc72f0bf09bf2c9397ddcd76194e74fdaf34466438e37b57ac8cbc46\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/b9/90/25a0195cf95fb5533db96f1c77ea3f296b7cc86ae8ae48e3dc\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60966 sha256=27ca74949951e595f122329fc4eee340dbf54a9dd61d9bfef5d98d2b47e4bb25\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/fa/b9/5c82b59d905f95542a192b883c0cc0082407ea2f54beb2f9e6\n",
            "Successfully built efficientnet-pytorch pretrainedmodels\n",
            "Installing collected packages: munch, huggingface-hub, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n",
            "Successfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.12.1 munch-2.5.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.2 timm-0.6.12\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "Successfully installed tokenizers-0.13.2 transformers-4.26.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.6/41.6 KB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (4.64.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install decord\n",
        "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu117\n",
        "!pip install pytorch-lightning\n",
        "!pip install pytorchvideo\n",
        "!pip install scikit-learn\n",
        "!pip install scikit-multilearn\n",
        "!pip install segmentation-models-pytorch\n",
        "!pip install transformers\n",
        "!pip install einops\n",
        "!pip install tqdm\n",
        "!git clone https://github.com/ugiugi0823/DACON-Car-Crash-Analysis.git\n",
        "!gdown \"1npn0T-pMOKw4hu39p2gbgaVq0podIpT0&confirm=t\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd DACON-Car-Crash-Analysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4Z8YLYUfNfH",
        "outputId": "06d289d5-9782-441b-d012-6773e71ad2cf"
      },
      "id": "a4Z8YLYUfNfH",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/DACON-Car-Crash-Analysis\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir checkpoint\n",
        "!mkdir submission"
      ],
      "metadata": {
        "id": "YSlP8xYuCHeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee1b3e5c-c971-4593-89b0-b2764dc40f98"
      },
      "id": "YSlP8xYuCHeq",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from zipfile import ZipFile\n",
        "import glob\n",
        "\n",
        "\n",
        "dir = '/content/'\n",
        "\n",
        "base_dir = '/content/DACON-Car-Crash-Analysis/data'\n",
        "\n",
        "ZipFile(dir + 'open.zip').extractall(base_dir)"
      ],
      "metadata": {
        "id": "SmpuVtKsCO1l"
      },
      "id": "SmpuVtKsCO1l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf9651e-e42f-4b43-a52c-54d8b6fb58bc",
      "metadata": {
        "tags": [],
        "id": "aaf9651e-e42f-4b43-a52c-54d8b6fb58bc"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "from einops import rearrange\n",
        "from decord import VideoReader\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from segmentation_models_pytorch.losses import FocalLoss\n",
        "from transformers import AutoModel, AutoImageProcessor, AutoConfig\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from pytorchvideo.transforms.transforms_factory import create_video_transform\n",
        "\n",
        "from sampler import MultilabelBalancedRandomSampler\n",
        "from apollo import Apollo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "b2f4247e-f74d-4323-8005-242038d992a9",
      "metadata": {
        "id": "b2f4247e-f74d-4323-8005-242038d992a9"
      },
      "outputs": [],
      "source": [
        "config = {\n",
        "    \"seed\":2023,\n",
        "    \"model_name\":\"facebook/timesformer-base-finetuned-k400\",\n",
        "    \"batch_size\":3,\n",
        "    \"learning_rate\":1e-5,\n",
        "    \"data_dir\":'./data',\n",
        "    \"checkpoint_dir\":'./checkpoint',\n",
        "    \"submission_dir\":'./submission',\n",
        "    \"n_classes\":(2,3,4,3),\n",
        "    \"label_dict\":{\n",
        "        -1:[-1,-1,-1,-1],\n",
        "        0:[0,0,0,0],\n",
        "        1:[1,1,1,1],\n",
        "        2:[1,1,1,2],\n",
        "        3:[1,1,2,1],\n",
        "        4:[1,1,2,2],\n",
        "        5:[1,1,3,1],\n",
        "        6:[1,1,3,2],\n",
        "        7:[1,2,1,1],\n",
        "        8:[1,2,1,2],\n",
        "        9:[1,2,2,1],\n",
        "        10:[1,2,2,2],\n",
        "        11:[1,2,3,1],\n",
        "        12:[1,2,3,2]\n",
        "    },\n",
        "    \"label_reverse_dict\":{\n",
        "        (0,0,0,0):0,\n",
        "        (1,1,1,1):1,\n",
        "        (1,1,1,2):2,\n",
        "        (1,1,2,1):3,\n",
        "        (1,1,2,2):4,\n",
        "        (1,1,3,1):5,\n",
        "        (1,1,3,2):6,\n",
        "        (1,2,1,1):7,\n",
        "        (1,2,1,2):8,\n",
        "        (1,2,2,1):9,\n",
        "        (1,2,2,2):10,\n",
        "        (1,2,3,1):11,\n",
        "        (1,2,3,2):12,\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pprint\n",
        "\n",
        "pprint.pprint(config['n_classes'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6j4eyIjLfnm",
        "outputId": "d81c7501-f422-41ff-f8e8-407974dc3172"
      },
      "id": "z6j4eyIjLfnm",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 3, 4, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "a7430352-4e4d-414b-a180-ec554b3c9441",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7430352-4e4d-414b-a180-ec554b3c9441",
        "outputId": "38f7dac6-9bfe-4c71-afbc-8897459ef19a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:lightning_fabric.utilities.seed:Global seed set to 2023\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2023"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "pl.seed_everything(config['seed'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "f0a1692b-89ab-4739-a668-a191d43d85d2",
      "metadata": {
        "id": "f0a1692b-89ab-4739-a668-a191d43d85d2"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(f\"{config['data_dir']}/train.csv\")\n",
        "test_df = pd.read_csv(f\"{config['data_dir']}/test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "04928136-a408-4278-acbb-6284073c853c",
      "metadata": {
        "id": "04928136-a408-4278-acbb-6284073c853c"
      },
      "outputs": [],
      "source": [
        "train_df['sample_id'] = train_df['sample_id'].apply(lambda x: int(x.split('_')[1]))\n",
        "test_df['sample_id'] = test_df['sample_id'].apply(lambda x: int(x.split('_')[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "a728f070-8d8f-4961-9258-bb482aea315c",
      "metadata": {
        "id": "a728f070-8d8f-4961-9258-bb482aea315c"
      },
      "outputs": [],
      "source": [
        "train_df['video_path'] = train_df['video_path'].apply(lambda x: config['data_dir'] + x[1:])\n",
        "test_df['video_path'] = test_df['video_path'].apply(lambda x: config['data_dir'] + x[1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "0403f478-2bb1-4ab6-8589-86d1ffc8e7c2",
      "metadata": {
        "id": "0403f478-2bb1-4ab6-8589-86d1ffc8e7c2"
      },
      "outputs": [],
      "source": [
        "test_df['label']=-1\n",
        "test_df['label_split'] = test_df['label'].apply(config['label_dict'].get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "7ba29cd0-c1da-43ab-a68c-b09688c70576",
      "metadata": {
        "id": "7ba29cd0-c1da-43ab-a68c-b09688c70576"
      },
      "outputs": [],
      "source": [
        "train_df['label_split'] = train_df['label'].apply(config['label_dict'].get)\n",
        "train_label_split = np.array(train_df['label_split'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_multi_hot = np.hstack([np.eye(n_class, dtype=np.int32)[train_label_split[:,idx]] for idx, n_class in enumerate(config['n_classes'])])\n",
        "train_df['label_multi_hot'] = train_label_multi_hot.tolist()"
      ],
      "metadata": {
        "id": "vi1YR1sKfyyE"
      },
      "id": "vi1YR1sKfyyE",
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5mvY9nZ1h4SQ",
        "outputId": "0db922e2-53da-401d-cb37-5a6b2020093e"
      },
      "id": "5mvY9nZ1h4SQ",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      sample_id                   video_path  label   label_split  \\\n",
              "0             0  ./data/train/TRAIN_0000.mp4      7  [1, 2, 1, 1]   \n",
              "1             1  ./data/train/TRAIN_0001.mp4      7  [1, 2, 1, 1]   \n",
              "2             2  ./data/train/TRAIN_0002.mp4      0  [0, 0, 0, 0]   \n",
              "3             3  ./data/train/TRAIN_0003.mp4      0  [0, 0, 0, 0]   \n",
              "4             4  ./data/train/TRAIN_0004.mp4      1  [1, 1, 1, 1]   \n",
              "...         ...                          ...    ...           ...   \n",
              "2693       2693  ./data/train/TRAIN_2693.mp4      3  [1, 1, 2, 1]   \n",
              "2694       2694  ./data/train/TRAIN_2694.mp4      5  [1, 1, 3, 1]   \n",
              "2695       2695  ./data/train/TRAIN_2695.mp4      0  [0, 0, 0, 0]   \n",
              "2696       2696  ./data/train/TRAIN_2696.mp4      0  [0, 0, 0, 0]   \n",
              "2697       2697  ./data/train/TRAIN_2697.mp4      0  [0, 0, 0, 0]   \n",
              "\n",
              "                           label_multi_hot  \n",
              "0     [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]  \n",
              "1     [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]  \n",
              "2     [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]  \n",
              "3     [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]  \n",
              "4     [0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0]  \n",
              "...                                    ...  \n",
              "2693  [0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0]  \n",
              "2694  [0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0]  \n",
              "2695  [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]  \n",
              "2696  [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]  \n",
              "2697  [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]  \n",
              "\n",
              "[2698 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e783c09-86a9-419b-8bfb-feee5b1edcdb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sample_id</th>\n",
              "      <th>video_path</th>\n",
              "      <th>label</th>\n",
              "      <th>label_split</th>\n",
              "      <th>label_multi_hot</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>./data/train/TRAIN_0000.mp4</td>\n",
              "      <td>7</td>\n",
              "      <td>[1, 2, 1, 1]</td>\n",
              "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>./data/train/TRAIN_0001.mp4</td>\n",
              "      <td>7</td>\n",
              "      <td>[1, 2, 1, 1]</td>\n",
              "      <td>[0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>./data/train/TRAIN_0002.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>./data/train/TRAIN_0003.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>./data/train/TRAIN_0004.mp4</td>\n",
              "      <td>1</td>\n",
              "      <td>[1, 1, 1, 1]</td>\n",
              "      <td>[0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2693</th>\n",
              "      <td>2693</td>\n",
              "      <td>./data/train/TRAIN_2693.mp4</td>\n",
              "      <td>3</td>\n",
              "      <td>[1, 1, 2, 1]</td>\n",
              "      <td>[0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2694</th>\n",
              "      <td>2694</td>\n",
              "      <td>./data/train/TRAIN_2694.mp4</td>\n",
              "      <td>5</td>\n",
              "      <td>[1, 1, 3, 1]</td>\n",
              "      <td>[0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2695</th>\n",
              "      <td>2695</td>\n",
              "      <td>./data/train/TRAIN_2695.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2696</th>\n",
              "      <td>2696</td>\n",
              "      <td>./data/train/TRAIN_2696.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2697</th>\n",
              "      <td>2697</td>\n",
              "      <td>./data/train/TRAIN_2697.mp4</td>\n",
              "      <td>0</td>\n",
              "      <td>[0, 0, 0, 0]</td>\n",
              "      <td>[1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2698 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e783c09-86a9-419b-8bfb-feee5b1edcdb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e783c09-86a9-419b-8bfb-feee5b1edcdb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e783c09-86a9-419b-8bfb-feee5b1edcdb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "4be86239-8eb6-4a4d-9b7c-08e5ae197ee1",
      "metadata": {
        "id": "4be86239-8eb6-4a4d-9b7c-08e5ae197ee1"
      },
      "outputs": [],
      "source": [
        "train_df_for_dataset, _ , val_df_for_dataset, _  = iterative_train_test_split(X=train_df.values, y=train_label_multi_hot, test_size=0.2)\n",
        "test_df_for_dataset = test_df.values"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_multi_hot_for_sampler = np.array(train_df_for_dataset[:,4].tolist())"
      ],
      "metadata": {
        "id": "V8i1WxzxfwUB"
      },
      "id": "V8i1WxzxfwUB",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "58f4029b-f6e6-4b17-82c3-fb898fcec84e",
      "metadata": {
        "id": "58f4029b-f6e6-4b17-82c3-fb898fcec84e"
      },
      "outputs": [],
      "source": [
        "class VideoDataset(Dataset):\n",
        "    def __init__(self, df_for_dataset, transform=None):\n",
        "        self.sample_id = df_for_dataset[:,0] # 1번부터 2698번\n",
        "        self.video_path = df_for_dataset[:,1] # 비디오 경로\n",
        "        self.label = df_for_dataset[:,2] # 1~12번 label\n",
        "        self.label_split = np.array(df_for_dataset[:,3].tolist()) # 4개의 class 로 나눈거\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sample_id)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sample_id = self.sample_id[idx]\n",
        "        video_path = self.video_path[idx]\n",
        "        vr = VideoReader(video_path)\n",
        "        video = torch.from_numpy(vr.get_batch(range(50)).asnumpy())\n",
        "        video = rearrange(video, 't h w c -> c t h w')\n",
        "        label = self.label[idx]\n",
        "        label_split = self.label_split[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            video = self.transform(video)\n",
        "        video = rearrange(video, 'c t h w -> t c h w')\n",
        "\n",
        "        sample = {\n",
        "            'sample_id':sample_id,\n",
        "            'video':video,\n",
        "            'label':label,\n",
        "            'label_split':label_split\n",
        "        }\n",
        "        \n",
        "        return sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "d84d5626-6b8b-4ea9-81a8-3320337d93d9",
      "metadata": {
        "id": "d84d5626-6b8b-4ea9-81a8-3320337d93d9"
      },
      "outputs": [],
      "source": [
        "model_config = AutoConfig.from_pretrained(config['model_name'])\n",
        "image_processor_config = AutoImageProcessor.from_pretrained(config['model_name'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "7612a650-4c4d-4f1a-a7f7-11c22ff6b39f",
      "metadata": {
        "id": "7612a650-4c4d-4f1a-a7f7-11c22ff6b39f"
      },
      "outputs": [],
      "source": [
        "train_transform = create_video_transform(\n",
        "    mode='train',\n",
        "    num_samples=model_config.num_frames,\n",
        "    video_mean = tuple(image_processor_config.image_mean),\n",
        "    video_std = tuple(image_processor_config.image_std),\n",
        "    crop_size = tuple(image_processor_config.crop_size.values())\n",
        ")\n",
        "\n",
        "val_transform = create_video_transform(\n",
        "    mode='val',\n",
        "    num_samples=model_config.num_frames,\n",
        "    video_mean = tuple(image_processor_config.image_mean),\n",
        "    video_std = tuple(image_processor_config.image_std),\n",
        "    crop_size = tuple(image_processor_config.crop_size.values())\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "2d1b230d-4ca8-43ce-b7ea-0003c8352f72",
      "metadata": {
        "id": "2d1b230d-4ca8-43ce-b7ea-0003c8352f72"
      },
      "outputs": [],
      "source": [
        "train_dataset = VideoDataset(train_df_for_dataset, transform=train_transform)\n",
        "val_dataset = VideoDataset(val_df_for_dataset, transform=val_transform)\n",
        "test_dataset = VideoDataset(test_df_for_dataset, transform=val_transform)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "b4b25026-b607-4f60-a500-49d1ee93fb49",
      "metadata": {
        "id": "b4b25026-b607-4f60-a500-49d1ee93fb49"
      },
      "outputs": [],
      "source": [
        "train_sampler = MultilabelBalancedRandomSampler(train_multi_hot_for_sampler)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size= config['batch_size'], sampler=train_sampler)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = config['batch_size']*2)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size = config['batch_size']*2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "69747543-ce8b-4f0c-aa58-de46c616490b",
      "metadata": {
        "id": "69747543-ce8b-4f0c-aa58-de46c616490b"
      },
      "outputs": [],
      "source": [
        "class PLVideoModel(pl.LightningModule):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.learning_rate = config['learning_rate']\n",
        "        self.model = AutoModel.from_pretrained(config['model_name'])\n",
        "        self.classifiers = nn.ModuleList([\n",
        "            nn.LazyLinear(n_class) for n_class in config['n_classes']\n",
        "        ])\n",
        "        self.loss = FocalLoss('multiclass')\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.model(x).last_hidden_state.mean(dim=1)\n",
        "        x_out = [classifier(x) for classifier in self.classifiers]\n",
        "        return x_out\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        video, label, label_split = batch['video'], batch['label'], batch['label_split']\n",
        "        y_hats = self.forward(batch[\"video\"])\n",
        "        loss = sum([self.loss(y_hats[i], batch[\"label_split\"][:,i]) for i in range(len(self.config['n_classes']))])\n",
        "        loss = loss/len(self.config['n_classes'])\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    '''\n",
        "    분기점\n",
        "    '''\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        video, label, label_split = batch['video'], batch['label'], batch['label_split']\n",
        "        y_hats = self.forward(batch[\"video\"])\n",
        "        step_output = [*y_hats, label]\n",
        "        return step_output\n",
        "    \n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        video, _, _ = batch['video'], batch['label'], batch['label_split']\n",
        "        y_hats = self.forward(batch[\"video\"])\n",
        "        step_output = y_hats\n",
        "        return step_output\n",
        "\n",
        "    def validation_epoch_end(self, step_outputs):\n",
        "        pred1, pred2, pred3, pred4, label = [], [], [], [], []\n",
        "        for step_output in step_outputs:\n",
        "            pred1.append(step_output[0])\n",
        "            pred2.append(step_output[1])\n",
        "            pred3.append(step_output[2])\n",
        "            pred4.append(step_output[3])\n",
        "            label.append(step_output[4])\n",
        "            \n",
        "        pred1 = torch.cat(pred1).argmax(1)\n",
        "        pred2 = torch.cat(pred2).argmax(1)\n",
        "        pred3 = torch.cat(pred3).argmax(1)\n",
        "        pred4 = torch.cat(pred4).argmax(1)\n",
        "        label = torch.cat(label).tolist()\n",
        "\n",
        "        pred = torch.stack([pred1,pred2,pred3,pred4],dim=1).cpu().detach().numpy().tolist()\n",
        "        pred = list(map(lambda x: self.config['label_reverse_dict'].get(tuple(x),0),pred))\n",
        "        \n",
        "        score = f1_score(label,pred, average='macro')\n",
        "        self.log(\"val_score\", score)\n",
        "        return score\n",
        "    \n",
        "    def post_preproc(self, step_outputs):\n",
        "        pred1, pred2, pred3, pred4 = [], [], [], []\n",
        "        for step_output in step_outputs:\n",
        "            pred1.append(step_output[0])\n",
        "            pred2.append(step_output[1])\n",
        "            pred3.append(step_output[2])\n",
        "            pred4.append(step_output[3])\n",
        "            \n",
        "        pred1 = torch.cat(pred1).argmax(1)\n",
        "        pred2 = torch.cat(pred2).argmax(1)\n",
        "        pred3 = torch.cat(pred3).argmax(1)\n",
        "        pred4 = torch.cat(pred4).argmax(1)\n",
        "\n",
        "        pred = torch.stack([pred1,pred2,pred3,pred4],dim=1).cpu().detach().numpy().tolist()\n",
        "        pred = list(map(lambda x: self.config['label_reverse_dict'].get(tuple(x),0),pred))\n",
        "\n",
        "        return pred\n",
        "            \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = Apollo(self.parameters(), lr=self.learning_rate)  #아폴로 쓰이는 순간~!\n",
        "        return [optimizer]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dbd5dbf9-b7f7-404b-9843-faae40e7eb0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535,
          "referenced_widgets": [
            "185b1f920e144605922b59fe24e5c5c2",
            "9ac6c74acb0543b18cce8c359af9483c",
            "d7f7dea01a46424d8f9c4c2b0511fca4",
            "8b26a1a3cc6649fe95ec2a5369c53d37",
            "bde0784dbd8b4145a46c35efcc261c9d",
            "bcc93a4adc9f44408ff20ab88d186a31",
            "c9c1fb00e7f54036b63af55a6d5ebda8",
            "46bbae9cc9464c0a8ae4da1fd5612402",
            "6fc8ecc86f174bdc8bbaff3cba8b7774",
            "a37f7002f5ac4194b68c36b738039f1e",
            "43d57257bcd044caab7f8a882c424518",
            "ab15ce4971f64da0951f5ce595df8c42",
            "dbce516662cf44b9b45130381b73a6ef",
            "a472bc4e358f444695982b341f47cb84",
            "62b35828b4e84d6c88298ea4e93c8582",
            "228c3f7c224d489fa10907a163447151",
            "c26ad4baf05846c0bbb3aea72d5a3bd1",
            "4859037d8c304102ab3b239fa7362c3f",
            "f4a8db4e93804f4687428b4301189b3c",
            "125bf8ff6a0f43d08b4d3f28a314848c",
            "54159b84bb3a4b14b27bc917c01ba2da",
            "f4ae727d5d4b47ebb3bd173fc137a9c8"
          ]
        },
        "id": "dbd5dbf9-b7f7-404b-9843-faae40e7eb0c",
        "outputId": "cd29be68-a2c3-417e-b92f-533b60effb01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at facebook/timesformer-base-finetuned-k400 were not used when initializing TimesformerModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing TimesformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "INFO:pytorch_lightning.utilities.rank_zero:Using 16bit None Automatic Mixed Precision (AMP)\n",
            "INFO:pytorch_lightning.utilities.rank_zero:GPU available: True (cuda), used: True\n",
            "INFO:pytorch_lightning.utilities.rank_zero:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.rank_zero:IPU available: False, using: 0 IPUs\n",
            "INFO:pytorch_lightning.utilities.rank_zero:HPU available: False, using: 0 HPUs\n",
            "INFO:pytorch_lightning.accelerators.cuda:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "INFO:pytorch_lightning.callbacks.model_summary:\n",
            "  | Name        | Type             | Params\n",
            "-------------------------------------------------\n",
            "0 | model       | TimesformerModel | 121 M \n",
            "1 | classifiers | ModuleList       | 0     \n",
            "2 | loss        | FocalLoss        | 0     \n",
            "-------------------------------------------------\n",
            "121 M     Trainable params\n",
            "0         Non-trainable params\n",
            "121 M     Total params\n",
            "242.518   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Sanity Checking: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "185b1f920e144605922b59fe24e5c5c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n",
            "/usr/local/lib/python3.8/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 4 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab15ce4971f64da0951f5ce595df8c42"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "checkpoint_callback = ModelCheckpoint(\n",
        "    monitor='val_score',\n",
        "    dirpath=config['checkpoint_dir'],\n",
        "    filename=f'{config[\"model_name\"]}'+'-{epoch:02d}-{train_loss:.4f}-{val_score:.4f}',\n",
        "    mode='max'\n",
        ")\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor=\"train_loss\",\n",
        "    patience=3,\n",
        "    verbose=False,\n",
        "    mode=\"min\"\n",
        ")\n",
        "\n",
        "pl_video_model = PLVideoModel(config)\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=100,\n",
        "    accelerator='auto', \n",
        "    precision=16,\n",
        "    callbacks=[early_stop_callback, checkpoint_callback]\n",
        "                    \n",
        ")\n",
        "trainer.fit(pl_video_model, train_dataloader, val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "531d95da-c86f-44e5-9a56-b16505bdc5d6",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "708d856ea4924f1fa6c11c3600742c3d"
          ]
        },
        "id": "531d95da-c86f-44e5-9a56-b16505bdc5d6",
        "outputId": "7e89091e-5fe2-4748-d3d6-1e1976a3e5d5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at facebook/timesformer-base-finetuned-k400 were not used when initializing TimesformerModel: ['classifier.weight', 'classifier.bias']\n",
            "- This IS expected if you are initializing TimesformerModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TimesformerModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\torch\\nn\\modules\\lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
            "  warnings.warn('Lazy modules are a new feature under heavy development '\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "You are using a CUDA device ('NVIDIA GeForce RTX 3070') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "C:\\Users\\dust\\anaconda3\\envs\\py310_torch1\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
            "  rank_zero_warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "708d856ea4924f1fa6c11c3600742c3d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Predicting: 0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pl_video_model_pretrained = PLVideoModel.load_from_checkpoint(\n",
        "    \"./checkpoint/facebook/timesformer-base-finetuned-k400-epoch=08-train_loss=0.1318-val_score=0.5356.ckpt\",\n",
        "    config=config\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(accelerator='auto')\n",
        "pred = trainer.predict(pl_video_model_pretrained, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fae171f4-24fe-4428-94e7-e2e920b20b88",
      "metadata": {
        "id": "fae171f4-24fe-4428-94e7-e2e920b20b88"
      },
      "outputs": [],
      "source": [
        "pred_post_proc = pl_video_model_pretrained.post_preproc(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53206209-b381-44e9-a27b-815db93db13d",
      "metadata": {
        "id": "53206209-b381-44e9-a27b-815db93db13d"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv(f\"{config['data_dir']}/sample_submission.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c14c78f9-1a7a-4a5b-8e32-b768e43ea392",
      "metadata": {
        "id": "c14c78f9-1a7a-4a5b-8e32-b768e43ea392"
      },
      "outputs": [],
      "source": [
        "submit['label'] = pred_post_proc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3cc42ee-4233-496b-98df-d7b08f0abe11",
      "metadata": {
        "id": "c3cc42ee-4233-496b-98df-d7b08f0abe11"
      },
      "outputs": [],
      "source": [
        "submit.to_csv(f\"{config['submission_dir']}/testsubmit.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c8a2770-efb1-460a-a9be-f5f81c7311d1",
      "metadata": {
        "id": "5c8a2770-efb1-460a-a9be-f5f81c7311d1"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "185b1f920e144605922b59fe24e5c5c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ac6c74acb0543b18cce8c359af9483c",
              "IPY_MODEL_d7f7dea01a46424d8f9c4c2b0511fca4",
              "IPY_MODEL_8b26a1a3cc6649fe95ec2a5369c53d37"
            ],
            "layout": "IPY_MODEL_bde0784dbd8b4145a46c35efcc261c9d"
          }
        },
        "9ac6c74acb0543b18cce8c359af9483c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bcc93a4adc9f44408ff20ab88d186a31",
            "placeholder": "​",
            "style": "IPY_MODEL_c9c1fb00e7f54036b63af55a6d5ebda8",
            "value": "Sanity Checking DataLoader 0: 100%"
          }
        },
        "d7f7dea01a46424d8f9c4c2b0511fca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46bbae9cc9464c0a8ae4da1fd5612402",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6fc8ecc86f174bdc8bbaff3cba8b7774",
            "value": 2
          }
        },
        "8b26a1a3cc6649fe95ec2a5369c53d37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a37f7002f5ac4194b68c36b738039f1e",
            "placeholder": "​",
            "style": "IPY_MODEL_43d57257bcd044caab7f8a882c424518",
            "value": " 2/2 [00:01&lt;00:00,  1.23it/s]"
          }
        },
        "bde0784dbd8b4145a46c35efcc261c9d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": "100%"
          }
        },
        "bcc93a4adc9f44408ff20ab88d186a31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9c1fb00e7f54036b63af55a6d5ebda8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46bbae9cc9464c0a8ae4da1fd5612402": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6fc8ecc86f174bdc8bbaff3cba8b7774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a37f7002f5ac4194b68c36b738039f1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d57257bcd044caab7f8a882c424518": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab15ce4971f64da0951f5ce595df8c42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dbce516662cf44b9b45130381b73a6ef",
              "IPY_MODEL_a472bc4e358f444695982b341f47cb84",
              "IPY_MODEL_62b35828b4e84d6c88298ea4e93c8582"
            ],
            "layout": "IPY_MODEL_228c3f7c224d489fa10907a163447151"
          }
        },
        "dbce516662cf44b9b45130381b73a6ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c26ad4baf05846c0bbb3aea72d5a3bd1",
            "placeholder": "​",
            "style": "IPY_MODEL_4859037d8c304102ab3b239fa7362c3f",
            "value": "Epoch 0:   5%"
          }
        },
        "a472bc4e358f444695982b341f47cb84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4a8db4e93804f4687428b4301189b3c",
            "max": 810,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_125bf8ff6a0f43d08b4d3f28a314848c",
            "value": 43
          }
        },
        "62b35828b4e84d6c88298ea4e93c8582": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54159b84bb3a4b14b27bc917c01ba2da",
            "placeholder": "​",
            "style": "IPY_MODEL_f4ae727d5d4b47ebb3bd173fc137a9c8",
            "value": " 43/810 [01:04&lt;19:01,  1.49s/it, loss=0.587, v_num=2]"
          }
        },
        "228c3f7c224d489fa10907a163447151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "c26ad4baf05846c0bbb3aea72d5a3bd1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4859037d8c304102ab3b239fa7362c3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f4a8db4e93804f4687428b4301189b3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125bf8ff6a0f43d08b4d3f28a314848c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "54159b84bb3a4b14b27bc917c01ba2da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ae727d5d4b47ebb3bd173fc137a9c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}